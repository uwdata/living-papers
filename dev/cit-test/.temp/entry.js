import { CiteRef } from '/Users/tunguyen/living-papers-testbed/src/components/cite-ref.js';
import { reference } from '/Users/tunguyen/living-papers-testbed/src/output/html/reference.js';
window.customElements.define('cite-ref', CiteRef);

window.addEventListener('DOMContentLoaded', () => {
  const root = document.querySelector('article');
  reference(root, [{"id":"Bullman:2018","doi":"0.23919/ICIF.2018.8455686","year":1991,"author":[{"given":"M.","family":"Bullmann"},{"given":"T.","family":"Fetzer"},{"given":"F.","family":"Ebner"},{"given":"F.","family":"Deinzer"},{"given":"M.","family":"Grzegorzek"}],"title":"Fast Kernel Density Estimation Using Gaussian Filter Approximation","venue":"Proc. International Conference on Information Fusion (FUSION)"},{"id":"doi:10.1145/3242587.3242600","doi":"10.1145/3242587.3242600","s2id":"4fca64e6dc4e803d3ed904c04c6845a9e6adc53e","year":2018,"author":[{"given":"Matthew","family":"Conlen","sequence":"first","affiliation":[{"name":"University of Washington, Seattle, WA, USA"}]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[{"name":"University of Washington, Seattle, WA, USA"}]}],"title":"Idyll: A Markup Language for Authoring and Publishing Interactive Articles on the Web","venue":"Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology","url":"https://www.semanticscholar.org/paper/4fca64e6dc4e803d3ed904c04c6845a9e6adc53e","abstract":"The web has matured as a publishing platform: news outlets regularly publish rich, interactive stories while technical writers use animation and interaction to communicate complex ideas. This style of interactive media has the potential to engage a large audience and more clearly explain concepts, but is expensive and time consuming to produce. Drawing on industry experience and interviews with domain experts, we contribute design tools to make it easier to author and publish interactive articles. We introduce Idyll, a novel \"compile-to-the-web\" language for web-based interactive narratives. Idyll implements a flexible article model, allowing authors control over document style and layout, reader-driven events (such as button clicks and scroll triggers), and a structured interface to JavaScript components. Through both examples and first-use results from undergraduate computer science students, we show how Idyll reduces the amount of effort and custom code required to create interactive articles.","tldr":"This work introduces Idyll, a novel \"compile-to-the-web\" language for web-based interactive narratives, and shows how Idyll reduces the amount of effort and custom code required to create interactive articles."},{"id":"Deriche:1990","doi":"10.1109/34.41386","s2id":"00a9e76e584127741f633ddc0d43779972171ec2","year":1990,"author":[{"given":"R.","family":"Deriche"}],"title":"Fast Algorithms for Low-Level Vision","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","url":"https://www.semanticscholar.org/paper/00a9e76e584127741f633ddc0d43779972171ec2","abstract":"A recursive filtering structure is proposed that drastically reduces the computational effort required for smoothing, performing the first and second directional derivatives, and carrying out the Laplacian of an image. These operations are done with a fixed number of multiplications and additions per output point independently of the size of the neighborhood considered. The key to the approach is, first, the use of an exponentially based filter family and, second, the use of the recursive filtering. Applications to edge detection problems and multiresolution techniques are considered, and an edge detector allowing the extraction of zero-crossings of an image with only 14 operations per output element at any resolution is proposed. Various experimental results are shown. >","tldr":"A recursive filtering structure is proposed that drastically reduces the computational effort required for smoothing, performing the first and second directional derivatives, and carrying out the Laplacian of an image."},{"id":"Deriche:1993","year":1993,"author":[{"given":"R.","family":"Deriche"}],"title":"Recursively implementing the Gaussian and its derivatives","venue":"INRIA Research Report 1893","url":"http://hal.inria.fr/docs/00/07/47/78/PDF/RR-1893.pdf"},{"id":"Jones:1983","doi":"10.1080/00949658308810650","s2id":"22cd4524838f5e06b809374b6bca24ba947b1607","year":1983,"author":[{"given":"M. C.","family":"Jones"},{"given":"H. W.","family":"Lotwick"}],"title":"On the errors involved in computing the empirical characteristic function","venue":"Journal of Statistical Computation and Simulation","url":"https://www.semanticscholar.org/paper/22cd4524838f5e06b809374b6bca24ba947b1607","abstract":"This paper considers discretisation errors involved in using the Fast Fourier Transform to compute the empirical characteristic function efficiently. A simple improvement to the usual histogram discretisation scheme is shown to reduce the mean square error considerably, as the grid size tends to zero. Simulation results show that the improvement is just as good in practical cases. The theoretical results are applied to the efficient calculation of kernel density estimates, described in Silverman (1982).","tldr":"A simple improvement to the usual histogram discretisation scheme is shown to reduce the mean square error considerably, as the grid size tends to zero."},{"id":"Scott:1985","doi":"10.1080/03610928508828980","s2id":"6bc7aa121a15bae1ca300e745b39a7392a510cc0","year":1985,"author":[{"given":"D. W.","family":"Scott"},{"given":"S. J.","family":"Sheather"}],"title":"Kernel density estimation with binned data","venue":"Communications in Statistics - Theory and Methods","url":"https://www.semanticscholar.org/paper/6bc7aa121a15bae1ca300e745b39a7392a510cc0","abstract":"Continuous data are often measured or used in binned or rounded form. In this paper we follow up on Hall's work analyzing the effect of using equally-spaced binned data in a kernel density estimator. It is shown that a surprisingly large amount of binning does not adversely affect the integrated mean squared error of a kernel estimate.","tldr":"It is shown that a surprisingly large amount of binning does not adversely affect the integrated mean squared error of a kernel estimate."},{"id":"Silverman:1982","doi":"10.2307/2347084","s2id":"ac387b2a1837a5aa294021900b664c4feeeb9cf9","year":1982,"author":[{"given":"B. W.","family":"Silverman"}],"title":"Algorithm AS 176: Kernel density estimation using the fast Fourier transform","venue":"Journal of the Royal Statistical Society, Series C (Applied Statistics)","url":"https://www.semanticscholar.org/paper/ac387b2a1837a5aa294021900b664c4feeeb9cf9"},{"id":"Toomanyauthors:2018","doi":"0.23919/ICIF.2018.8455686","year":1991,"author":[{"given":"M.","family":"Bullmann"},{"given":"T.","family":"Fetzer"},{"given":"F.","family":"Ebner"},{"given":"F.","family":"Deinzer"},{"given":"M.","family":"Grzegorzek","suffix":"M."},{"given":"T.","family":"Fetzer"},{"given":"F.","family":"Ebner"},{"given":"F.","family":"Deinzer"},{"given":"M.","family":"Grzegorzek","suffix":"M."},{"given":"T.","family":"Fetzer"},{"given":"F.","family":"Ebner"},{"given":"F.","family":"Deinzer"},{"given":"M.","family":"Grzegorzek","suffix":"M."},{"given":"T.","family":"Fetzer"},{"given":"F.","family":"Ebner"},{"given":"F.","family":"Deinzer"},{"given":"M.","family":"Grzegorzek","suffix":"M."},{"given":"T.","family":"Fetzer"},{"given":"F.","family":"Ebner"},{"given":"F.","family":"Deinzer"},{"given":"M.","family":"Grzegorzek"}],"title":"Fast Kernel Density Estimation Using Gaussian Filter Approximation","venue":"Proc. International Conference on Information Fusion (FUSION)"},{"id":"Wand:1994","doi":"10.1080/10618600.1994.10474656","s2id":"ba5b46d7719296e6555432e23c9ff82e7187f13c","year":1994,"author":[{"given":"M. P.","family":"Wand"}],"title":"Fast Computation of Multivariate Kernel Estimators","venue":"Journal of Statistical Computation and Simulation","url":"https://www.semanticscholar.org/paper/ba5b46d7719296e6555432e23c9ff82e7187f13c","abstract":"Abstract Multivariate extensions of binning techniques for fast computation of kernel estimators are described and examined. Several questions arising from this multivariate extension are addressed. The choice of binning rule is discussed, and it is demonstrated that linear binning leads to substantial accuracy improvements over simple binning. An investigation into the most appropriate means of computing the multivariate discrete convolutions required for binned kernel estimators is also given. The results of an empirical study indicate that, in multivariate settings, the fast Fourier transform offers considerable time savings compared to direct calculation of convolutions."},{"id":"Wells:1986","doi":"10.1109/TPAMI.1986.4767776","s2id":"305b55e2fef5679878313933c1bf4ee0251ce53c","year":1986,"author":[{"given":"W. M.","family":"Wells"}],"title":"Efficient synthesis of Gaussian filters by cascaded uniform filters","venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","url":"https://www.semanticscholar.org/paper/305b55e2fef5679878313933c1bf4ee0251ce53c","abstract":"Gaussian filtering is an important tool in image processing and computer vision. In this paper we discuss the background of Gaussian filtering and look at some methods for implementing it. Consideration of the central limit theorem suggests using a cascade of ``simple'' filters as a means of computing Gaussian filters. Among ``simple'' filters, uniform-coefficient finite-impulse-response digital filters are especially economical to implement. The idea of cascaded uniform filters has been around for a while [13], [16]. We show that this method is economical to implement, has good filtering characteristics, and is appropriate for hardware implementation. We point out an equivalence to one of Burt's methods [1], [3] under certain circumstances. As an extension, we describe an approach to implementing a Gaussian Pyramid which requires approximately two addition operations per pixel, per level, per dimension. We examine tradeoffs in choosing an algorithm for Gaussian filtering, and finally discuss an implementation.","tldr":"This paper describes an approach to implementing a Gaussian Pyramid which requires approximately two addition operations per pixel, per level, per dimension, and examines tradeoffs in choosing an algorithm for Gaussian filtering."}]);
});